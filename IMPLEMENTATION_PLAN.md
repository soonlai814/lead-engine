# Lead Signal Engine â€” Implementation Plan

## Overview
This document outlines the detailed implementation plan for building the Lead Signal Engine, broken down into phases with specific tasks, dependencies, and acceptance criteria.

## Current Status

**âœ… Phase 0: Foundation Setup â€” COMPLETE**  
**âœ… Phase 1: Hiring End-to-End â€” COMPLETE**  
**ðŸš§ Phase 2: Launch Signals â€” NEXT UP**

**Last Updated:** Current session  
**Setup Guide:** See [SETUP_GUIDE.md](SETUP_GUIDE.md) for installation instructions

---

## Phase 0: Foundation Setup âœ… **COMPLETED**

### Tasks
1. âœ… Project structure setup
2. âœ… Python package configuration (`pyproject.toml`)
3. âœ… Database models (PostgreSQL + SQLAlchemy)
4. âœ… Config YAML files (query_packs, keywords, scoring, runtime)
5. âœ… CLI skeleton
6. âœ… Module stubs with function signatures
7. âœ… Environment setup (.env.example template)
8. âœ… Logging infrastructure (structlog for JSON logs)

### Deliverables
- âœ… Complete project structure matching Section 16
- âœ… All config files populated with starter data
- âœ… Database schema ready (SQLAlchemy models)
- âœ… CLI commands functional (stub implementations)
- âœ… All modules have proper interfaces
- âœ… README.md with quick start guide
- âœ… .gitignore configured
- âœ… Implementation plan document

### Acceptance Criteria
- âœ… `python -m lead_engine run --help` works (CLI structure ready)
- âœ… Config files load without errors (YAML files created)
- âœ… Database models defined (PostgreSQL + SQLAlchemy)
- âœ… All imports resolve (module structure complete)

### Status: **COMPLETE** âœ…
**Completed Date:** Current session  
**Next Phase:** Phase 1 - Hiring End-to-End

---

## Phase 1: Hiring End-to-End (MVP Core) âœ… **COMPLETED**

### Goal
Build a working pipeline that discovers companies via ATS boards, classifies them, scores them, and exports MVP leads.

### Tasks

#### 1.1 SERP Discovery Module âœ…
- âœ… Implement `providers/serpapi.py`
  - âœ… SerpAPI client wrapper
  - âœ… Query execution with pagination
  - âœ… Error handling and retries
  - âœ… Rate limiting per query pack
- âœ… Store raw results in `SerpResult` table
- âœ… Integration ready with real SerpAPI

**Dependencies:** None  
**Status:** âœ… Complete

#### 1.2 URL Normalization Module âœ…
- âœ… Implement `normalize/url_normalizer.py`
  - âœ… Generic URL canonicalization
  - âœ… Query param removal (utm_*, ref, etc.)
  - âœ… Trailing slash normalization
- âœ… Implement `normalize/ats_normalizer.py`
  - âœ… Greenhouse normalization
  - âœ… Lever normalization
  - âœ… Ashby normalization
  - âœ… Workable normalization
  - âœ… SmartRecruiters normalization
  - âœ… Teamtailor normalization
  - âœ… Recruitee normalization

**Dependencies:** None  
**Status:** âœ… Complete

#### 1.3 Discovery Target Management âœ…
- âœ… Implement deduplication logic in `orchestrator.py`
  - âœ… Normalize URLs from SERP results
  - âœ… Dedupe by `source_url_normalized`
  - âœ… Track `seen_count`, `first_seen_at`, `last_seen_at`
- âœ… Store `DiscoveryTarget` records

**Dependencies:** 1.1, 1.2  
**Status:** âœ… Complete

#### 1.4 Crawler & Fetcher Module âœ…
- âœ… Implement `crawl/fetcher.py`
  - âœ… HTTP client with httpx
  - âœ… Timeouts (connect: 5s, read: 15s)
  - âœ… Retries with exponential backoff (max 2)
  - âœ… Rate limiting (per-domain: 1 req/sec, global: 60 req/min)
  - âœ… 429/503 handling with cooldown
  - âœ… Content caching (by normalized URL, TTL from config)
  - âœ… Content hash (sha256) for change detection
- âœ… Store cache metadata

**Dependencies:** None  
**Status:** âœ… Complete

#### 1.5 ATS Parsers âœ…
- âœ… Implement `crawl/parsers/ats_greenhouse.py`
  - âœ… Parse job listings from Greenhouse board
  - âœ… Extract job titles
  - âœ… Count engineering roles
  - âœ… Map roles to taxonomy (backend, frontend, ml_ai, etc.)
  - âœ… Extract company website URL (best effort)
- âœ… Implement `crawl/parsers/ats_lever.py`
- âœ… Implement `crawl/parsers/ats_ashby.py`
- âœ… Shared helper functions for role matching

**Dependencies:** 1.4  
**Status:** âœ… Complete

#### 1.6 Domain Resolver âœ…
- âœ… Implement `resolve/domain_resolver.py`
  - âœ… Extract company domain from ATS parsed data
  - âœ… Fallback: extract from ATS URL patterns
  - âœ… Normalize to root domain
  - âœ… Store in `Company` table

**Dependencies:** 1.5  
**Status:** âœ… Complete

#### 1.7 Signal Snapshot Storage âœ…
- âœ… Store `SignalSnapshot` records
  - âœ… Link to `company_domain`
  - âœ… Store `source_type`, `source_url_normalized`
  - âœ… Store `signals` list and `signal_details` dict
  - âœ… Track `content_hash` for change detection

**Dependencies:** 1.5, 1.6  
**Status:** âœ… Complete

#### 1.8 Rule-Based Classifier âœ…
- âœ… Implement `classify/rule_classifier.py`
  - âœ… Extract text content from HTML
  - âœ… Count keywords (product vs services vs staffing)
  - âœ… Apply decision rules from config
  - âœ… Compute confidence score
  - âœ… Return classification with reasons
- âœ… Store in `Company` table

**Dependencies:** 1.4, 1.6  
**Status:** âœ… Complete

#### 1.9 Scoring Module âœ…
- âœ… Implement `score/scoring.py`
  - âœ… Load scoring weights from `config/scoring.yaml`
  - âœ… Compute MVP intent score from signals
  - âœ… Apply penalties for services/staffing
  - âœ… Return score breakdown dict
- âœ… Implement `score/router.py`
  - âœ… Apply routing rules based on classification
  - âœ… Determine `route_flag` (outreach_mvp_client | outreach_partnership | ignore)
  - âœ… Recommend outreach channel
- âœ… Implement `score/outreach_note.py`
  - âœ… Generate 1-line outreach note from top evidence
  - âœ… Use templates from config
- âœ… Store `Lead` records

**Dependencies:** 1.7, 1.8  
**Status:** âœ… Complete

#### 1.10 CSV Export âœ…
- âœ… Implement `export/csv_exporter.py`
  - âœ… Export MVP leads to `mvp_clients_ranked.csv`
  - âœ… Sort by `mvp_intent_score` descending
  - âœ… Include all required columns
  - âœ… Handle JSON serialization for `score_breakdown_json`
- âœ… Export partnership targets CSV

**Dependencies:** 1.9  
**Status:** âœ… Complete

#### 1.11 Orchestrator Integration âœ…
- âœ… Wire all modules together in `orchestrator.py`
  - âœ… Load configs
  - âœ… Execute SERP discovery for hiring query packs
  - âœ… Process discovery targets through pipeline
  - âœ… Handle errors gracefully
  - âœ… Log metrics per run
- âœ… CLI integration (`cli.py run --source hiring`)

**Dependencies:** All above  
**Status:** âœ… Complete

### Phase 1 Acceptance Criteria
- âœ… Can run `python -m lead_engine run --source hiring`
- âœ… Discovers ATS boards from SERP
- âœ… Normalizes URLs correctly
- âœ… Parses at least 3 ATS types (Greenhouse, Lever, Ashby)
- âœ… Classifies companies correctly (rule-based classification implemented)
- âœ… Generates MVP leads CSV with scores
- âœ… All metrics logged (SERP calls, targets discovered, etc.)

### Status: **COMPLETE** âœ…
**Completed Date:** Current session  
**Next Phase:** Phase 2 - Launch Signals

### Phase 1 Implementation Summary
All 11 sub-tasks completed. The pipeline now:
1. Discovers ATS boards via SerpAPI
2. Normalizes and deduplicates URLs
3. Fetches and caches pages with rate limiting
4. Parses job listings from Greenhouse, Lever, and Ashby
5. Resolves company domains
6. Classifies business types using rule-based keyword matching
7. Scores leads (MVP intent and partnership fit)
8. Routes leads to appropriate pipelines
9. Generates outreach notes
10. Exports ranked CSV files

**Ready for testing and Phase 2 development.**

---

## Phase 2: Launch Signals

### Goal
Add launch discovery and parsing to enrich lead signals.

### Tasks

#### 2.1 Launch SERP Queries
- [ ] Add launch query packs to `config/query_packs.yaml`
  - Show HN queries
  - Generic launch queries
- [ ] Test SERP discovery for launch source type

**Dependencies:** Phase 1.1  
**Estimated:** 1 day

#### 2.2 Launch Parser
- [ ] Implement `crawl/parsers/launch_generic.py`
  - Parse launch pages/posts
  - Extract launch date (best effort)
  - Extract product name
  - Extract product URL
  - Detect recency signals (0-30d, 31-90d)
  - Detect builder post indicators

**Dependencies:** Phase 1.4  
**Estimated:** 3-4 days

#### 2.3 Launch Signal Integration
- [ ] Update scoring to include launch recency boost
- [ ] Update outreach note generator for launch signals
- [ ] Test end-to-end launch â†’ lead flow

**Dependencies:** 2.1, 2.2, Phase 1.9  
**Estimated:** 1 day

### Phase 2 Acceptance Criteria
- âœ… Launch discovery works via SERP
- âœ… Launch dates extracted (best effort)
- âœ… Recency signals correctly applied to scoring
- âœ… Launch leads appear in MVP CSV

### Phase 2 Total Estimate: 5-6 days

---

## Phase 3: Funding/Accelerator Signals

### Goal
Add funding and accelerator discovery to boost lead scores.

### Tasks

#### 3.1 Funding SERP Queries
- [ ] Add funding query packs
  - Accelerator directory queries
  - Funding round announcement queries
- [ ] Test SERP discovery

**Dependencies:** Phase 1.1  
**Estimated:** 1 day

#### 3.2 Funding Parser
- [ ] Implement `crawl/parsers/funding_generic.py`
  - Parse accelerator directory pages
  - Parse funding announcement pages
  - Extract accelerator name / batch
  - Extract funding round (pre-seed/seed/A)
  - Extract funding date (best effort)
  - Extract company domain

**Dependencies:** Phase 1.4  
**Estimated:** 4-5 days

#### 3.3 Funding Signal Integration
- [ ] Update scoring for accelerator/funding boosts
- [ ] Update outreach note generator
- [ ] Test end-to-end flow

**Dependencies:** 3.1, 3.2, Phase 1.9  
**Estimated:** 1 day

### Phase 3 Acceptance Criteria
- âœ… Funding discovery works
- âœ… Accelerator membership detected
- âœ… Funding rounds extracted
- âœ… Scoring boosts applied correctly

### Phase 3 Total Estimate: 6-7 days

---

## Phase 4: Ecosystem Signals

### Goal
Add ecosystem/community discovery (Web3, AI builders, etc.).

### Tasks

#### 4.1 Ecosystem SERP Queries
- [ ] Add ecosystem query packs
  - Web3 ecosystem directories
  - AI builder programs
- [ ] Test SERP discovery

**Dependencies:** Phase 1.1  
**Estimated:** 1 day

#### 4.2 Ecosystem Parser
- [ ] Implement `crawl/parsers/ecosystem_generic.py`
  - Parse directory pages
  - Parse grant/hackathon pages
  - Extract ecosystem tag (Base/Solana/etc.)
  - Extract program type (directory|grant|hackathon)
  - Extract program name
  - Extract project domain

**Dependencies:** Phase 1.4  
**Estimated:** 4-5 days

#### 4.3 Ecosystem Signal Integration
- [ ] Update scoring for ecosystem boosts
- [ ] Update outreach note generator
- [ ] Test end-to-end flow

**Dependencies:** 4.1, 4.2, Phase 1.9  
**Estimated:** 1 day

### Phase 4 Acceptance Criteria
- âœ… Ecosystem discovery works
- âœ… Ecosystem tags extracted
- âœ… Scoring boosts applied
- âœ… Partnership targets CSV includes ecosystem signals

### Phase 4 Total Estimate: 6-7 days

---

## Phase 5: AI Fallback + Enhancements

### Goal
Add AI classification fallback and optional review UI.

### Tasks

#### 5.1 AI Classifier Module
- [ ] Implement `classify/ai_classifier.py`
  - Trigger conditions (unknown or low confidence)
  - Prepare minimal inputs (meta, nav, excerpt)
  - Call AI provider (TBD - OpenAI/Anthropic)
  - Parse strict JSON response
  - Cache results by domain
  - Cost controls (max calls/day)
- [ ] Integration with rule classifier

**Dependencies:** Phase 1.8  
**Estimated:** 3-4 days

#### 5.2 Partnership Pipeline Export âœ…
- âœ… Update `export/csv_exporter.py` (Completed in Phase 1.10)
  - âœ… Export partnership targets CSV
  - âœ… Include partnership fit score
  - âœ… Include suggested partnership angle

**Dependencies:** Phase 1.9  
**Status:** âœ… Complete (implemented in Phase 1.10)

#### 5.3 Optional: Streamlit Review UI
- [ ] Create simple UI to review leads
  - View MVP leads table
  - View partnership targets table
  - Filter by score, source type
  - Mark leads as contacted/replied/etc.
  - Update lead status in database

**Dependencies:** All phases  
**Estimated:** 3-4 days (optional)

### Phase 5 Acceptance Criteria
- âœ… AI classification works for unknown/low-confidence cases
- âœ… Cost controls enforced
- âœ… Partnership CSV exported correctly
- âœ… (Optional) Review UI functional

### Phase 5 Total Estimate: 7-9 days (4-5 if UI skipped)

---

## Overall Timeline Estimate

- **Phase 0 (Foundation):** 1-2 days âœ… **COMPLETE**
- **Phase 1 (Hiring MVP):** 22-28 days âœ… **COMPLETE**
- **Phase 2 (Launch):** 5-6 days ðŸš§ **NEXT**
- **Phase 3 (Funding):** 6-7 days
- **Phase 4 (Ecosystem):** 6-7 days
- **Phase 5 (AI + Enhancements):** 7-9 days

**Completed:** 2 phases (Foundation + Hiring MVP)  
**Remaining:** 3-4 phases (Launch, Funding, Ecosystem, AI)  
**Total Estimated Remaining: 24-29 days** (approximately 1 month for remaining phases)

---

## Risk Mitigation

### High-Risk Areas
1. **SerpAPI Rate Limits / Costs**
   - Mitigation: Implement daily caps, monitor usage, cache aggressively
   
2. **ATS Parsing Reliability**
   - Mitigation: Start with 3 major ATS, add fallbacks, test with real data
   
3. **Classification Accuracy**
   - Mitigation: Start rule-based, tune keywords, add AI fallback in Phase 5
   
4. **PostgreSQL Setup Complexity**
   - Mitigation: Use Docker Compose for local dev, clear migration scripts

### Dependencies to Watch
- SerpAPI availability and pricing
- ATS site structure changes (parsers may break)
- PostgreSQL connection pooling for production

---

## Success Metrics

### Phase 1 Success
- â‰¥50 discovered targets/day
- â‰¥70% classification precision
- MVP CSV generated with scores

### Full System Success (Phase 5)
- â‰¥50-200 discovered targets/day
- â‰¥20-50 high-score MVP leads/week
- â‰¥10-30 partnership targets/week
- â‰¥70% precision on top-50 MVP leads

---

## Next Steps After Phase 0

1. Set up PostgreSQL database (local + production)
2. Get SerpAPI API key and test connection
3. Collect sample ATS board HTMLs for parser development
4. Start Phase 1.1 (SERP Discovery Module)

